{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import tarfile\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('russian')\n",
    "\n",
    "from string import punctuation\n",
    "# punkt= [p for p in punctuation] + [\"`\", \"``\" ,\"''\", \"'\"]\n",
    "punkt= [p for p in punctuation] + [\"`\", \"``\" ,\"''\", \"'\", '\"','\"\"','\"\"\"','«','»']\n",
    "\n",
    "\n",
    "import gensim\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import fasttext\n",
    "import pymorphy3\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Загрузка данных из файла\n",
    "# df = pd.read_csv('shorted_data_combined.csv')\n",
    "\n",
    "\n",
    "\n",
    "# # Удаление пунктуации и стоп-слов из колонки 'topic'\n",
    "# df['topic'] = df['topic'].apply(\n",
    "#     lambda x: ' '.join([word.lower() for word in nltk.word_tokenize(x) if word.lower() not in stop and word not in punkt])\n",
    "# )\n",
    "\n",
    "# # Сохранение измененных данных в новый файл\n",
    "# df.to_csv('del_pun_stop_words.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('del_pun_stop_words.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title     9802\n",
       "topic    10695\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем максимальное количество новостей для каждой темы\n",
    "max_news_per_topic = 1000\n",
    "\n",
    "# Группируем данные по теме и выбираем не более 1000 новостей из каждой темы\n",
    "df2 = df2.groupby('topic').sample(max_news_per_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Министр регионального развития Грузии ушел в о...</td>\n",
       "      <td>бывший ссср</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В Киеве допустили ракетный удар России по Украине</td>\n",
       "      <td>бывший ссср</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Заместитель Тимошенко пригрозил фальсификатора...</td>\n",
       "      <td>бывший ссср</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title        topic\n",
       "0  Министр регионального развития Грузии ушел в о...  бывший ссср\n",
       "1  В Киеве допустили ракетный удар России по Украине  бывший ссср\n",
       "2  Заместитель Тимошенко пригрозил фальсификатора...  бывший ссср"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9000 entries, 70 to 6652\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   9000 non-null   object\n",
      " 1   topic   9000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 210.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Topic  Count  Percentage\n",
      "0        бывший ссср   1000   11.111111\n",
      "1             забота   1000   11.111111\n",
      "2      наука техника   1000   11.111111\n",
      "3        путешествия   1000   11.111111\n",
      "4             россия   1000   11.111111\n",
      "5  силовые структуры   1000   11.111111\n",
      "6              спорт   1000   11.111111\n",
      "7      строительство   1000   11.111111\n",
      "8          экономика   1000   11.111111\n"
     ]
    }
   ],
   "source": [
    "# topic_counts = df['topic'].value_counts(normalize=True)\n",
    "# print(topic_counts)\n",
    "\n",
    "topic_counts = df2['topic'].value_counts()\n",
    "topic_percentage = df2['topic'].value_counts(normalize=True) * 100\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'Topic': topic_counts.index,\n",
    "    'Count': topic_counts.values,\n",
    "    'Percentage': topic_percentage.values\n",
    "})\n",
    "\n",
    "print(result_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    'Россия': '0',\n",
    "    'Экономика': '1',\n",
    "    'Силовые структуры': '2',\n",
    "    'Бывший СССР': '3',\n",
    "    'Спорт': '4',\n",
    "    'Забота': '5',\n",
    "    'Строительство': '6',\n",
    "    'Путешествия': '7',\n",
    "    'Наука техника': '8'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy3 import MorphAnalyzer\n",
    "import pymorphy3_dicts_ru\n",
    "# Создание объекта лемматизатора\n",
    "lemmatizer = MorphAnalyzer(path=pymorphy3_dicts_ru.get_path(),lang='ru')\n",
    "\n",
    "# Пример текста для лемматизации\n",
    "text1 = \"Кошки любят  лазить по деревьям.\"\n",
    "text2 = \"Кошки любят  лазить по деревьям.\"\n",
    "text = ' br '.join([text1,text2])\n",
    "# Лемматизация слов в тексте\n",
    "lemmatized_text = ' '.join([lemmatizer.parse(word)[0].normal_form for word in text.split()])\n",
    "print(lemmatized_text.split('br'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title    500\n",
      "topic    500\n",
      "dtype: int64\n",
      "title    1000\n",
      "topic    1000\n",
      "dtype: int64\n",
      "title    1500\n",
      "topic    1500\n",
      "dtype: int64\n",
      "title    2000\n",
      "topic    2000\n",
      "dtype: int64\n",
      "title    2500\n",
      "topic    2500\n",
      "dtype: int64\n",
      "title    3000\n",
      "topic    3000\n",
      "dtype: int64\n",
      "title    3500\n",
      "topic    3500\n",
      "dtype: int64\n",
      "title    4000\n",
      "topic    4000\n",
      "dtype: int64\n",
      "title    4500\n",
      "topic    4500\n",
      "dtype: int64\n",
      "title    5000\n",
      "topic    5000\n",
      "dtype: int64\n",
      "title    5500\n",
      "topic    5500\n",
      "dtype: int64\n",
      "title    6000\n",
      "topic    6000\n",
      "dtype: int64\n",
      "title    6500\n",
      "topic    6500\n",
      "dtype: int64\n",
      "title    7000\n",
      "topic    7000\n",
      "dtype: int64\n",
      "title    7500\n",
      "topic    7500\n",
      "dtype: int64\n",
      "title    8000\n",
      "topic    8000\n",
      "dtype: int64\n",
      "title    8500\n",
      "topic    8500\n",
      "dtype: int64\n",
      "title    9000\n",
      "topic    9000\n",
      "dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from pymorphy3 import MorphAnalyzer\n",
    "import pymorphy3_dicts_ru\n",
    "# import pandas as pd\n",
    "\n",
    "# Создание объекта лемматизатора\n",
    "lemmatizer = MorphAnalyzer(path=pymorphy3_dicts_ru.get_path(), lang='ru')\n",
    "\n",
    "# Разбивка DataFrame на блоки по 500 строк\n",
    "block_size = 500\n",
    "\n",
    "num_blocks = len(df2) // block_size \n",
    "cheker = 0\n",
    "# # Новый DataFrame для хранения лемматизированных данных\n",
    "lemmatized_df = pd.DataFrame(columns=['title', 'topic'])\n",
    "checker = 0\n",
    "for i in range(num_blocks):\n",
    "    start_idx = i * block_size\n",
    "    end_idx = (i + 1) * block_size\n",
    "\n",
    "\n",
    "    block_data = df2.iloc[start_idx:end_idx]\n",
    "\n",
    "    # Объединение текста в блоке через 'br'\n",
    "    block_text = ' ||| '.join(block_data['title'])\n",
    "\n",
    "    # # Лемматизация слов в тексте\n",
    "    lemmatized_text = ' '.join([lemmatizer.parse(word)[0].normal_form for word in block_text.split(' ')])\n",
    "    lemmatized_text = lemmatized_text.split('|||')\n",
    "    # проверяем на всякий\n",
    "    # print(len(lemmatized_text),lemmatized_text)\n",
    "  \n",
    "\n",
    "\n",
    "#     # Создание DataFrame для блока с лемматизированными данными\n",
    "    lemmatized_block_df = pd.DataFrame({'title': lemmatized_text, 'topic': block_data['topic']})\n",
    "    # checker += \n",
    "    # print(lemmatized_block_df.count())\n",
    "#     # Добавление лемматизированных данных в основной DataFrame\n",
    "    lemmatized_df = pd.concat([lemmatized_df, lemmatized_block_df])\n",
    "    print(lemmatized_df.count())\n",
    "\n",
    "# # # Вывод первых 3 строк нового DataFrame\n",
    "# print(lemmatized_df.head(3))\n",
    "\n",
    "\n",
    "print(cheker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9000 entries, 70 to 6652\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   title   9000 non-null   object\n",
      " 1   topic   9000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 210.9+ KB\n"
     ]
    }
   ],
   "source": [
    "lemmatized_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_mapping = {\n",
    "    'Россия': '0',\n",
    "    'Экономика': '1',\n",
    "    'Силовые структуры': '2',\n",
    "    'Бывший СССР': '3',\n",
    "    'Спорт': '4',\n",
    "    'Забота': '5',\n",
    "    'Строительство': '6',\n",
    "    'Путешествия': '7',\n",
    "    'Наука техника': '8'\n",
    "}\n",
    "topic_mapping = {key.lower(): value for key, value in topic_mapping.items()}\n",
    "\n",
    "# Заменить значения в колонке 'topic' на их числовые представления из словаря\n",
    "lemmatized_df['topic'] = lemmatized_df['topic'].replace(topic_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>мэр ивано-франковск присоединиться к бессрочны...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>южный осетия выставлять грузия счёт на 18 мил...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>министр региональный развитие грузия уйти в о...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>чичваркин прилететь в киев для проведение мас...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>донецкий фильтровальный станция обесточить из...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title topic\n",
       "70   мэр ивано-франковск присоединиться к бессрочны...     3\n",
       "758   южный осетия выставлять грузия счёт на 18 мил...     3\n",
       "0     министр региональный развитие грузия уйти в о...     3\n",
       "535   чичваркин прилететь в киев для проведение мас...     3\n",
       "774   донецкий фильтровальный станция обесточить из...     3"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = lemmatized_df['title']\n",
    "topics = lemmatized_df['topic']\n",
    "X = titles.tolist()\n",
    "Y = topics.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_train, title_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все записано!\n"
     ]
    }
   ],
   "source": [
    "with open('train_data_titles.txt', 'w+', encoding='utf-8') as tr:\n",
    "    for idx in range(len(title_train)):\n",
    "        # tr.write('__label__' + y_train[idx]+' '+title_train[idx]+'\\n')\n",
    "        tr.write('__label__' + f'{y_train[idx]}'+' '+title_train[idx]+'\\n')\n",
    "        \n",
    "with open('test_data_titles.txt', 'w+', encoding='utf-8') as te:\n",
    "    for idx in range(len(title_test)):\n",
    "        # te.write('__label__' + y_test[idx]+' '+title_test[idx]+'\\n')        \n",
    "        te.write('__label__' + f'{y_test[idx]}'+' '+title_test[idx]+'\\n')    \n",
    "print('Все записано!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 531 ms\n",
      "Wall time: 259 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft_model = fasttext.train_supervised(input='train_data_titles.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    try:\n",
    "        sent = word_tokenize(sent)\n",
    "        return [word for word in sent if word not in stop and word not in punkt]\n",
    "    \n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "def lemmatize(sent):\n",
    "    try:\n",
    "        return \" \".join([lemmatizer.normal_forms(word)[0] for word in sent])\n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "    \n",
    "# def preprocess_sent(sent):\n",
    "#     return lemmatize(tokenize(sent))\n",
    "\n",
    "\n",
    "def preprocess_sent(sent):\n",
    "    try:\n",
    "        tokenized_sent = tokenize(sent)\n",
    "        lemmatized_sent = lemmatize(tokenized_sent)\n",
    "        return lemmatized_sent\n",
    "    except Exception as e:\n",
    "        print(f\"Error in preprocess_sent: {e}\")\n",
    "        return \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__1', '__label__8', '__label__2'),\n",
       " array([0.36269757, 0.13101771, 0.13025342]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model.predict(preprocess_sent('Акула съела банкира: акции банка упали на 25%'), k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.41 s\n",
      "Wall time: 1.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft_model_p1 = fasttext.train_supervised(input='train_data_titles.txt', epoch=20, wordNgrams=2, loss='hs', lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 0.6955555555555556, 0.6955555555555556)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_model_p1.test('test_data_titles.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 22min 11s\n",
      "Wall time: 6min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ft_model_p2 = fasttext.train_supervised(input='train_data_titles.txt', autotuneValidationFile='test_data_titles.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 0.76, 0.76)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ft_model_p2.test('test_data_titles.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate: 0.3761170672491951 \n",
      "Best epochs: 48 \n",
      "Best_word_Ngrams: 1\n"
     ]
    }
   ],
   "source": [
    "# print(f'Best learning rate: {ft_model_p2.lr} \\nBest epochs: {ft_model_p2.epoch} \\nBest_word_Ngrams: {ft_model_p2.wordNgrams}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data = pd.read_csv('test_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Фото: «Фонтанка.ру»ПоделитьсяЭкс-министру обор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>В начале февраля 2023 года в Пушкинском районе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Фото: Andy Bao / Getty Images Анастасия Борисо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Если вы хотели, но так и не съездили на море л...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Сергей Пиняев Фото: Алексей Филиппов / РИА Нов...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  Фото: «Фонтанка.ру»ПоделитьсяЭкс-министру обор...\n",
       "1  В начале февраля 2023 года в Пушкинском районе...\n",
       "2  Фото: Andy Bao / Getty Images Анастасия Борисо...\n",
       "3  Если вы хотели, но так и не съездили на море л...\n",
       "4  Сергей Пиняев Фото: Алексей Филиппов / РИА Нов..."
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26275 entries, 0 to 26274\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   content  26275 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 205.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Удаление пунктуации и стоп-слов из колонки 'topic'\n",
    "# test_data['content'] = test_data['content'].apply(\n",
    "#     lambda x: ' '.join([word.lower() for word in nltk.word_tokenize(x) if word.lower() not in stop and word not in punkt])\n",
    "# )\n",
    "\n",
    "# # Сохранение измененных данных в новый файл\n",
    "# # test_data.to_csv('del_psw_test_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26275"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_data['content'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content    1000\n",
      "dtype: int64\n",
      "content    2000\n",
      "dtype: int64\n",
      "content    3000\n",
      "dtype: int64\n",
      "content    4000\n",
      "dtype: int64\n",
      "content    5000\n",
      "dtype: int64\n",
      "content    6000\n",
      "dtype: int64\n",
      "content    7000\n",
      "dtype: int64\n",
      "content    8000\n",
      "dtype: int64\n",
      "content    9000\n",
      "dtype: int64\n",
      "content    10000\n",
      "dtype: int64\n",
      "content    11000\n",
      "dtype: int64\n",
      "content    12000\n",
      "dtype: int64\n",
      "content    13000\n",
      "dtype: int64\n",
      "content    14000\n",
      "dtype: int64\n",
      "content    15000\n",
      "dtype: int64\n",
      "content    16000\n",
      "dtype: int64\n",
      "content    17000\n",
      "dtype: int64\n",
      "content    18000\n",
      "dtype: int64\n",
      "content    19000\n",
      "dtype: int64\n",
      "content    20000\n",
      "dtype: int64\n",
      "content    21000\n",
      "dtype: int64\n",
      "content    22000\n",
      "dtype: int64\n",
      "content    23000\n",
      "dtype: int64\n",
      "content    24000\n",
      "dtype: int64\n",
      "content    25000\n",
      "dtype: int64\n",
      "content    26275\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# from pymorphy3 import MorphAnalyzer\n",
    "# import pymorphy3_dicts_ru\n",
    "# # import pandas as pd\n",
    "\n",
    "# # Создание объекта лемматизатора\n",
    "# lemmatizer = MorphAnalyzer(path=pymorphy3_dicts_ru.get_path(), lang='ru')\n",
    "\n",
    "# # Разбивка DataFrame на блоки по 500 строк\n",
    "# block_size = 1000\n",
    "\n",
    "# num_blocks = len(test_data) // block_size \n",
    "\n",
    "# # # Новый DataFrame для хранения лемматизированных данных\n",
    "# lemmatized_df = pd.DataFrame(columns=['content'])\n",
    "\n",
    "# for i in range(num_blocks):\n",
    "#     start_idx = i * block_size\n",
    "#     end_idx = (i + 1) * block_size\n",
    "#     if end_idx == 26000:\n",
    "#         end_idx = test_data['content'].shape[0]\n",
    "#     # print(i,start_idx,end_idx)\n",
    "\n",
    "#     block_data = test_data.iloc[start_idx:end_idx]\n",
    "\n",
    "#     # Объединение текста в блоке через 'br'\n",
    "#     block_text = ' ||| '.join(block_data['content'])\n",
    "\n",
    "#     # # Лемматизация слов в тексте\n",
    "#     lemmatized_text = ' '.join([lemmatizer.parse(word)[0].normal_form for word in block_text.split(' ')])\n",
    "#     lemmatized_text = lemmatized_text.split('|||')\n",
    "#     # проверяем на всякий\n",
    "#     # print(len(lemmatized_text),lemmatized_text)\n",
    "  \n",
    "\n",
    "\n",
    "# #     # Создание DataFrame для блока с лемматизированными данными\n",
    "#     lemmatized_block_df = pd.DataFrame({'content': lemmatized_text})\n",
    "#     # print(lemmatized_block_df.count())\n",
    "# #     # Добавление лемматизированных данных в основной DataFrame\n",
    "#     lemmatized_df = pd.concat([lemmatized_df, lemmatized_block_df])\n",
    "#     print(lemmatized_df.count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatized_df.to_csv('lemm_test_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('lemm_test_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание меток для каждого заголовка новости\n",
    "predicted_labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in test_data['content']:  # Замените 'content' на реальное имя столбца с заголовками\n",
    "    # Удаление символа новой строки, если он присутствует\n",
    "    title = title.replace('\\n', ' ')\n",
    "    # Предсказание меток\n",
    "    # labels, probs = ft_model_p1.predict(title)\n",
    "    labels, probs = ft_model_p2.predict(title)\n",
    "    # print(labels, probs)\n",
    "    predicted_labels.append(labels[0])\n",
    "\n",
    "# Добавление предсказанных меток в тестовые данные\n",
    "test_data['predicted_label'] = predicted_labels\n",
    "\n",
    "# Вывод результата\n",
    "# print(test_data[['content', 'predicted_label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>фото фонтанка.р поделитьсяэкс-министр оборона ...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>начало февраль 2023 год пушкинский район санк...</td>\n",
       "      <td>__label__6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>фото andy bao getty images анастасия борисов ...</td>\n",
       "      <td>__label__4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>хотеть съездить море летом-2023 — читать далё...</td>\n",
       "      <td>__label__5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>сергей пиняев фото алексей филипп риа новость...</td>\n",
       "      <td>__label__4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content predicted_label\n",
       "0  фото фонтанка.р поделитьсяэкс-министр оборона ...      __label__2\n",
       "1   начало февраль 2023 год пушкинский район санк...      __label__6\n",
       "2   фото andy bao getty images анастасия борисов ...      __label__4\n",
       "3   хотеть съездить море летом-2023 — читать далё...      __label__5\n",
       "4   сергей пиняев фото алексей филипп риа новость...      __label__4"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание DataFrame с результатами\n",
    "pre_result_df = pd.DataFrame({'content': test_data['content'], 'predicted_label': test_data['predicted_label']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>topic</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>фото фонтанка.р поделитьсяэкс-министр оборона ...</td>\n",
       "      <td>__label__2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>начало февраль 2023 год пушкинский район санк...</td>\n",
       "      <td>__label__6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>фото andy bao getty images анастасия борисов ...</td>\n",
       "      <td>__label__4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>хотеть съездить море летом-2023 — читать далё...</td>\n",
       "      <td>__label__5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>сергей пиняев фото алексей филипп риа новость...</td>\n",
       "      <td>__label__4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content predicted_label  topic  \\\n",
       "0  фото фонтанка.р поделитьсяэкс-министр оборона ...      __label__2      2   \n",
       "1   начало февраль 2023 год пушкинский район санк...      __label__6      6   \n",
       "2   фото andy bao getty images анастасия борисов ...      __label__4      4   \n",
       "3   хотеть съездить море летом-2023 — читать далё...      __label__5      5   \n",
       "4   сергей пиняев фото алексей филипп риа новость...      __label__4      4   \n",
       "\n",
       "   index  \n",
       "0      0  \n",
       "1      1  \n",
       "2      2  \n",
       "3      3  \n",
       "4      4  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pre_result_df['topic'] = test_data['predicted_label'].copy().str.replace('__label__', '').astype(int)\n",
    "pre_result_df['index'] = test_data.index.copy()\n",
    "pre_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic  index\n",
       "0      2      0\n",
       "1      6      1\n",
       "2      4      2\n",
       "3      5      3\n",
       "4      4      4"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pre_result_df[['topic','index']].copy()\n",
    "\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('result_3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
